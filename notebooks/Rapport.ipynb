{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b73d960-025d-4110-9e34-1bdf834a4fac",
   "metadata": {},
   "source": [
    "# Rapport - Classification d’images  \n",
    "Comparaison de CNN et d’une méthode classique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943db76-ef14-4adb-8dc8-1b659e0bbc5f",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Ce projet vise à comparer plusieurs approches de classification d’images sur différents jeux de données, en étudiant leurs performances, leur complexité et leur comportement face à la variabilité des données.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c837bf3-e0d2-42be-9a2a-a5beb7e5b829",
   "metadata": {},
   "source": [
    "## 2. Objectif global\n",
    "\n",
    "L’objectif principal de ce projet est de comparer trois approches de classification d’images :\n",
    "\n",
    "- Un CNN à 2 couches de convolution\n",
    "- Un CNN à 3 couches de convolution\n",
    "- Une méthode classique basée sur ORB + Bag of Visual Words (BoVW) + SVM\n",
    "\n",
    "Ces méthodes ont été évaluées sur trois jeux de données distincts, afin d’analyser leur capacité de généralisation et leur robustesse selon la complexité des images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c563e69-c603-41f0-920a-e16ce30ee4c1",
   "metadata": {},
   "source": [
    "### Choix des architectures CNN\n",
    "\n",
    "Le CNN à 2 couches de convolution a été choisi comme modèle de référence (baseline). Cette architecture simple permet :\n",
    "- D’établir un premier niveau de performance\n",
    "- De limiter le temps d’entraînement\n",
    "- De mieux comprendre l’impact des couches de convolution sur l’extraction de caractéristiques\n",
    "\n",
    "Le CNN à 3 couches de convolution constitue une extension naturelle de cette baseline. L’ajout d’une couche supplémentaire permet :\n",
    "- D’extraire des caractéristiques plus abstraites et hiérarchisées\n",
    "- D’évaluer l’impact de la profondeur du réseau sur les performances\n",
    "- De comparer le compromis entre complexité du modèle et gain de précision\n",
    "\n",
    "Ce choix progressif (2 puis 3 convolutions) permet une comparaison équitable, en modifiant uniquement la profondeur du réseau tout en conservant une structure globale similaire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6d48b-a101-4faf-9eda-50418bc3b31c",
   "metadata": {},
   "source": [
    "### Choix de la méthode ORB + BoVW + SVM\n",
    "\n",
    "En complément des CNN, une méthode classique basée sur ORB, Bag of Visual Words et SVM a été implémentée afin de disposer d’un point de comparaison ne reposant pas sur l’apprentissage profond.\n",
    "\n",
    "Ce choix est motivé par :\n",
    "- La popularité historique de cette approche en vision par ordinateur\n",
    "- Son faible coût computationnel comparé aux CNN\n",
    "- Sa capacité à fournir des résultats corrects sur des datasets simples\n",
    "\n",
    "Cette méthode permet également d’évaluer l’intérêt réel des CNN face à une approche plus traditionnelle, notamment lorsque les ressources de calcul sont limitées.\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c48d15-46e9-4896-b9e5-1e3070e12425",
   "metadata": {},
   "source": [
    "## 3. Jeux de données\n",
    "\n",
    "Trois datasets ont été utilisés tout au long du projet. Ils diffèrent par :\n",
    "\n",
    "- Le nombre de classes\n",
    "- La diversité visuelle\n",
    "- La taille et la résolution des images\n",
    "- La difficulté globale de la tâche de classification\n",
    "\n",
    "Chaque dataset a été séparé en ensembles d’entraînement et de validation afin d’évaluer les performances des modèles de manière cohérente.\n",
    "\n",
    "Dire les propriété de chaque base et expliquer nos choix : CNN 2 CNN 3 Transfert Learning Image Net et oRB. \n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb88082-7aec-47b5-a3a9-314d95ededb4",
   "metadata": {},
   "source": [
    "## 4. Comparaison des résultats par dataset (CNN 2 conv vs CNN 3 conv vs ORB+BoVW+SVM)\n",
    "\n",
    "### MNIST (10 classes)\n",
    "\n",
    "- CNN 2 convolutions\n",
    "  - Meilleure accuracy validation : 99,36 %\n",
    "  - Early stopping : déclenché à l’epoch 19, meilleur modèle restauré à l’epoch 14 \n",
    "\n",
    "- CNN 3 convolutions\n",
    "  - Meilleure accuracy validation : 98,95 %\n",
    "  - Early stopping : déclenché à l’epoch 17, meilleur modèle restauré à l’epoch 12\n",
    "\n",
    "- ORB + BoVW + SVM\n",
    "  - Accuracy test : 63,73 % \n",
    "\n",
    "#### Analyse :\n",
    "Sur MNIST, les deux CNN atteignent des performances très élevées (proche de 99%), ce qui montre qu’une architecture peu profonde suffit souvent sur un dataset simple et très structuré. Ici, le modèle CNN 2 convolutions fait même légèrement mieux que le 3 convolutions, ce qui suggère que l’ajout de profondeur n’apporte pas forcément un gain dans ce contexte (et peut légèrement compliquer l’optimisation).  \n",
    "En comparaison, ORB+BoVW+SVM reste nettement en dessous, car la méthode repose sur des descripteurs locaux et capture moins bien la forme globale des chiffres.\n",
    "\n",
    "### Dogs vs Cats (classification binaire)\n",
    "\n",
    "- CNN 2 convolutions\n",
    "  - Meilleure accuracy validation : 78,2 %\n",
    "  - Perte de validation minimale : 0,456\n",
    "  - Early stopping : déclenché à l’epoch 13, meilleur modèle restauré à l’epoch 10\n",
    "\n",
    "- CNN 3 convolutions\n",
    "  - Meilleure accuracy validation : 80,2 %\n",
    "  - Perte de validation minimale : 0,434\n",
    "  - Early stopping : déclenché à l’epoch 17, meilleur modèle restauré à l’epoch 14\n",
    "\n",
    "- ORB + BoVW + SVM\n",
    "  - Accuracy test : 69,3 %\n",
    "\n",
    "#### Analyse :\n",
    "Sur le dataset Dogs vs Cats, l’ajout d’une troisième couche de convolution permet une amélioration notable des performances, avec un gain d’environ 2 pourcent en accuracy sur l’ensemble de validation et une perte plus faible. Cela indique une meilleure capacité du modèle à extraire des caractéristiques discriminantes telles que les textures, formes et motifs globaux des animaux.\n",
    "\n",
    "Le CNN à 2 convolutions offre néanmoins un compromis intéressant entre performances et temps d’entraînement. À l’inverse, la méthode ORB + BoVW + SVM montre des performances plus limitées. Bien qu’elle reste au-dessus du hasard, elle peine à capturer la variabilité visuelle importante des images naturelles, ce qui explique l’écart observé avec les CNN.\n",
    "\n",
    "### Intel Image Classification (6 classes)\n",
    "\n",
    "- CNN 2 convolutions\n",
    "  - Meilleure accuracy validation : 82,1 %\n",
    "  - Perte de validation : 0,51\n",
    "\n",
    "- CNN 3 convolutions\n",
    "  - Meilleure accuracy validation : 84,8 %\n",
    "  - Perte de validation : 0,45\n",
    "\n",
    "- ORB + BoVW + SVM\n",
    "  - Accuracy test : 48,8 %\n",
    "\n",
    "#### Analyse :\n",
    "Sur le dataset Intel Image Classification, qui constitue le cas le plus complexe du projet, l’impact de la profondeur du réseau est particulièrement visible. Le CNN à 3 convolutions surpasse clairement le modèle à 2 convolutions, avec une meilleure précision et une perte de validation plus faible, traduisant une meilleure généralisation.\n",
    "\n",
    "La méthode ORB + BoVW + SVM atteint une accuracy d’environ 49 %, ce qui reste supérieur au hasard (16,7 % pour 6 classes), mais largement inférieur aux CNN. Cette différence s’explique par la difficulté de représenter la structure globale des scènes à l’aide de descripteurs locaux uniquement, notamment lorsque plusieurs classes présentent de fortes similarités visuelles.\n",
    "\n",
    "Ces résultats ont conduit à explorer plusieurs pistes d’optimisation, présentées dans la section suivante.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3aeb2-7976-4625-8de1-42e934dce5ff",
   "metadata": {},
   "source": [
    "## 5. Nettoyage et préparation des données\n",
    "\n",
    "Avant l’entraînement des différents modèles, une phase de nettoyage et de préparation des jeux de données a été réalisée. Cette étape est essentielle afin de garantir la qualité des données d’entrée et d’éviter des erreurs ou biais lors de l’apprentissage.\n",
    "\n",
    "### Gestion des images corrompues ou illisibles\n",
    "\n",
    "Lors de l’exploration des datasets, en particulier Dogs vs Cats et Intel Image Classification, certaines images se sont révélées corrompues, partiellement téléchargées ou impossibles à charger correctement par les bibliothèques de traitement d’images.\n",
    "\n",
    "Ces images ont été détectées lors de la phase de chargement des données et supprimées du jeu de données, afin d’éviter :\n",
    "- Des erreurs lors de l’entraînement\n",
    "- Des interruptions de l’exécution des scripts\n",
    "- Une dégradation de la qualité de l’apprentissage\n",
    "\n",
    "### Normalisation et redimensionnement des images\n",
    "\n",
    "Les images des datasets Dogs vs Cats et Intel présentent des tailles et des formats variés. Afin de garantir une entrée cohérente pour les réseaux de neurones convolutifs, toutes les images ont été :\n",
    "\n",
    "- Redimensionnées à une taille fixe\n",
    "- Converties dans un format compatible\n",
    "- Normalisées (valeurs de pixels ramenées dans un intervalle standard)\n",
    "\n",
    "Cette étape permet d’assurer une convergence plus stable des modèles et une comparaison équitable entre les différentes architectures.\n",
    "\n",
    "### Équilibrage et séparation des données\n",
    "\n",
    "Les jeux de données ont été divisés en ensembles d’entraînement et de validation de manière cohérente. Une attention particulière a été portée à conserver une répartition équilibrée des classes afin d’éviter un biais en faveur d’une classe dominante, en particulier pour la classification binaire Dogs vs Cats.\n",
    "\n",
    "### Cas particulier du dataset MNIST\n",
    "\n",
    "Le dataset MNIST étant déjà normalisé, équilibré et largement utilisé comme référence académique, aucune étape de nettoyage supplémentaire n’a été nécessaire. Seules des opérations de normalisation et de séparation entraînement/validation ont été appliquées.\n",
    "\n",
    "\n",
    "En résumé, cette phase de nettoyage et de préparation des données a permis de garantir des données fiables et cohérentes, condition indispensable à l’obtention de résultats reproductibles et à une comparaison pertinente des différentes méthodes de classification.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2111a22b-c3d2-4135-9873-86af82ae9e5c",
   "metadata": {},
   "source": [
    "## 6. Essais explorés mais non retenus\n",
    "\n",
    "Au cours du projet, plusieurs pistes d’optimisation ont été explorées afin d’améliorer les performances des modèles. Toutefois, certaines d’entre elles n’ont pas été conservées dans la version finale, soit en raison de gains de performance limités, soit à cause de contraintes computationnelles importantes. Dans plusieurs cas, l’augmentation du temps d’entraînement et de la complexité ne justifiait pas les améliorations obtenues.\n",
    "\n",
    "\n",
    "### Variation de la taille des batchs\n",
    "\n",
    "Différentes tailles de batch ont été testées lors de l’entraînement des CNN. Des batchs plus petits ont parfois permis une meilleure stabilité de l’apprentissage, mais ont entraîné une augmentation significative du temps d’entraînement, rendant les expérimentations beaucoup plus longues à exécuter.  \n",
    "\n",
    "À l’inverse, des batchs plus grands ont accéléré certaines phases d’apprentissage, mais ont souvent conduit à une convergence moins stable et à des performances de validation légèrement inférieures.\n",
    "\n",
    "Dans l’ensemble, ces variations n’ont pas apporté d’amélioration significative et reproductible des résultats, alors qu’elles pouvaient fortement ralentir l’entraînement. Une taille de batch intermédiaire a donc été retenue, offrant un compromis satisfaisant entre stabilité, performances et temps de calcul.\n",
    "\n",
    "\n",
    "### Ajustement des hyperparamètres avancés\n",
    "\n",
    "Plusieurs ajustements supplémentaires ont également été testés, notamment :\n",
    "- Des taux de dropout plus élevés\n",
    "- Des variations du learning rate\n",
    "- L’utilisation de régularisations plus agressives\n",
    "\n",
    "Ces modifications ont généralement conduit à des temps d’entraînement plus longs et parfois à une instabilité de l’apprentissage, sans apporter de gain de performance clair et durable sur l’ensemble des datasets. Dans certains cas, les améliorations observées étaient marginales et ne compensaient pas la complexité supplémentaire introduite.\n",
    "\n",
    "Nous avons donc décidé de ne pas garder ces ajustements dans la version finale.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b446b-d693-429b-97be-405f7a4c31de",
   "metadata": {},
   "source": [
    "## 7. Stratégies d’entraînement et de régularisation des CNN\n",
    "\n",
    "Afin d’assurer un entraînement stable et une comparaison équitable entre les différentes architectures CNN, plusieurs mécanismes communs ont été mis en place pour l’ensemble des expériences.\n",
    "\n",
    "### Early stopping\n",
    "\n",
    "Le mécanisme d’early stopping a été utilisé afin de limiter le surapprentissage. L’entraînement est interrompu automatiquement lorsque la performance sur l’ensemble de validation cesse de s’améliorer pendant un certain nombre d’époques consécutives (patience). Le modèle conserve alors les poids correspondant à la meilleure performance observée.\n",
    "\n",
    "Ce choix permet :\n",
    "- D’éviter un surentraînement inutile\n",
    "- De réduire le temps de calcul\n",
    "- De sélectionner un modèle généralisant mieux\n",
    "\n",
    "### Checkpointing des modèles\n",
    "\n",
    "Un système de checkpoints a été mis en place afin de sauvegarder les poids du modèle à chaque epoch (ou lorsque la métrique de validation s’améliore). Cette stratégie permet :\n",
    "- De conserver une trace des différentes étapes d’apprentissage\n",
    "- De restaurer le meilleur modèle après l’early stopping\n",
    "- D’analyser a posteriori l’évolution des performances\n",
    "\n",
    "### Choix du nombre d’époques\n",
    "\n",
    "Le nombre maximal d’époques a été fixé à 20 pour l’ensemble des CNN. Cette valeur constitue un compromis entre :\n",
    "- Une durée d’entraînement raisonnable\n",
    "- Une convergence suffisante des modèles\n",
    "\n",
    "Dans la majorité des cas, l’early stopping est déclenché avant d’atteindre ce nombre maximal, ce qui confirme que cette limite est suffisante pour permettre au modèle de converger.\n",
    "\n",
    "### Suivi des performances par epoch\n",
    "\n",
    "À chaque epoch, les métriques de loss et accuracy ont été enregistrées sur les ensembles d’entraînement et de validation. Ce suivi permet :\n",
    "- D’analyser la dynamique d’apprentissage\n",
    "- De détecter d’éventuels phénomènes de surapprentissage\n",
    "- De comparer finement les comportements des CNN à 2 et 3 couches de convolution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffafde3a-c37a-4958-9dc2-8e201a9c3ae5",
   "metadata": {},
   "source": [
    "## 8. Problèmes rencontrés et solutions\n",
    "\n",
    "Au cours du projet, plusieurs difficultés ont été rencontrées lors de la mise en œuvre et de l’entraînement des différents modèles de classification d’images. Cette section présente les principaux problèmes identifiés ainsi que les solutions apportées afin d’assurer la stabilité des expériences et la fiabilité des résultats.\n",
    "\n",
    "### Surapprentissage des modèles CNN\n",
    "\n",
    "L’un des principaux problèmes observés concerne le surapprentissage, en particulier pour les architectures les plus complexes et sur les datasets de taille limitée. Ce phénomène se manifestait par une amélioration continue des performances sur l’ensemble d’entraînement, tandis que l’accuracy de validation stagnait ou diminuait.\n",
    "\n",
    "Solution apportée :\n",
    "- Mise en place d’un mécanisme d’early stopping basé sur la performance de validation\n",
    "- Restauration automatique des poids correspondant à la meilleure epoch\n",
    "- Utilisation de dropout afin de limiter la dépendance excessive à certaines caractéristiques\n",
    "\n",
    "Ces solutions ont permis d’améliorer la capacité de généralisation des modèles et de stabiliser l’apprentissage.\n",
    "\n",
    "### Temps d’entraînement élevés\n",
    "\n",
    "L’entraînement des CNN, en particulier avec des architectures plus profondes ou des paramètres plus coûteux, a entraîné des temps de calcul importants. Ce problème était accentué lors des tests d’optimisation (variation des batchs, des hyperparamètres ou de la résolution des images).\n",
    "\n",
    "Solution apportée :\n",
    "- Limitation du nombre maximal d’époques\n",
    "- Utilisation systématique de l’early stopping pour interrompre les entraînements non prometteurs\n",
    "- Abandon des configurations offrant des gains marginaux au regard du temps de calcul supplémentaire\n",
    "\n",
    "Ces choix ont permis de conserver des temps d’entraînement raisonnables sans dégrader les performances finales.\n",
    "\n",
    "\n",
    "### Sensibilité aux hyperparamètres\n",
    "\n",
    "Les performances des modèles CNN se sont révélées sensibles à certains hyperparamètres, notamment le learning rate, la taille des batchs et le taux de dropout. Des valeurs inadaptées pouvaient conduire à une convergence lente ou instable.\n",
    "\n",
    "Solution apportée :\n",
    "- Tests progressifs et contrôlés des hyperparamètres\n",
    "- Conservation de configurations simples et robustes\n",
    "- Évitement des réglages trop agressifs susceptibles de dégrader la stabilité de l’apprentissage\n",
    "\n",
    "Cette approche a permis d’obtenir des résultats reproductibles et cohérents sur l’ensemble des datasets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
